[{"":"","# of input views (e.g. 18 for 18-camera system)":"","Abstract":"Here we present a machine learning framework and model implementation that can learn to simulate a wide variety of challenging physical domains, involving fluids, rigid solids, and deformable materials interacting with one another. Our framework---which we term Graph Network-based Simulators (GNS)---represents the state of a physical system with particles, expressed as nodes in a graph, and computes dynamics via learned message-passing. Our results show that our model can generalize from single-timestep predictions with thousands of particles during training, to different initial conditions, thousands of timesteps, and at least an order of magnitude more particles at test time. Our model was robust to hyperparameter choices across various evaluation metrics: the main determinants of long-term performance were the number of message-passing steps, and mitigating the accumulation of error by corrupting the training data with noise. Our GNS framework advances the state-of-the-art in learned physical simulation, and holds promise for solving a wide range of complex forward and inverse problems.","Authors (format: First Last, First Middle Last, ...)":"Alvaro Sanchez-Gonzalez, Jonathan Godwin, Tobias Pfaff, Rex Ying, Jure Leskovec, Peter W. Battaglia","Bibtex (e.g. @inproceedings...)":"@inproceedings{DBLP:conf/icml/Sanchez-Gonzalez20,\n  author    = {Alvaro Sanchez{-}Gonzalez and\n               Jonathan Godwin and\n               Tobias Pfaff and\n               Rex Ying and\n               Jure Leskovec and\n               Peter W. Battaglia},\n  title     = {Learning to Simulate Complex Physics with Graph Networks},\n  booktitle = {Proceedings of the 37th International Conference on Machine Learning,\n               {ICML} 2020, 13-18 July 2020, Virtual Event},\n  series    = {Proceedings of Machine Learning Research},\n  volume    = {119},\n  pages     = {8459--8468},\n  publisher = {{PMLR}},\n  year      = {2020},\n  url       = {http://proceedings.mlr.press/v119/sanchez-gonzalez20a.html},\n  timestamp = {Tue, 15 Dec 2020 17:40:19 +0100},\n  biburl    = {https://dblp.org/rec/conf/icml/Sanchez-Gonzalez20.bib},\n  bibsource = {dblp computer science bibliography, https://dblp.org}\n}","Bibtex Name":"DBLP:conf/icml/Sanchez-Gonzalez20","Citation Count":"","Code Release (Github link, or enter \"Coming soon\")":"","Coordinates all at once":"","Data Release (link)":"","Dataset(s) used (e.g. Tanks and Temples)":"","Date released":"14/9/2020","Direct/Indirect Neural Field (one or more dimension built into the network e.g. 2D CNN + z)":"","Does your work use coordinate(s) as neural network input(s)?":"","Email Address":"","Feature-as-input (coordinate samples feature grid, but coordinate is not supplied as input)":"","Frequency/Positional Encoding":"","Geometry proxy (for non-visual computing papers, choose \"N/A\")":"","Inputs":"","Is the PDF linked to arXiv?":"Yes (almost done)","Keywords":"Graph Neural Networks, forward simulation, GNS, GNNs, message passing, encoder-processor-decoder, physical simulation","Lighting":"","New entry or update existing?":"","Nickname (e.g. DeepSDF)":"","PDF link (arXiv perferred)":"https://arxiv.org/pdf/2002.09405.pdf","Project webpage link":"","Reconstructs Geometry Only (i.e. no color texture) (for non-visual computing papers, choose \"N/A\")":"","Rendering time (FPS)":"","Supplement PDF (link)":"","Supplement video (link, comma separated if multiple exists)":"","Talk/Video (link, Youtube preferred)":"","Title":"Learning to Simulate Complex Physics with Graph Networks","Training time (hr)":"","UID":"1","Venue & Year (e.g. NeurIPS 2022, ARXIV 2021)":"ICML 2020","Venue no Year":"ICML","Year (corresponding to venue e.g. released in 2021, accepted to CVPR 2022, then put \"2022\" for this entry, and \"2021\" for the above)":"2020","\ufeffTimestamp":"14/9/2020 16:52"},{"":"","# of input views (e.g. 18 for 18-camera system)":"","Abstract":"Mesh-based simulations are central to modeling complex physical systems in many disciplines across science and engineering. Mesh representations support powerful numerical integration methods and their resolution can be adapted to strike favorable trade-offs between accuracy and efficiency. However, high-dimensional scientific simulations are very expensive to run, and solvers and parameters must often be tuned individually to each system studied. Here we introduce MeshGraphNets, a framework for learning mesh-based simulations using graph neural networks. Our model can be trained to pass messages on a mesh graph and to adapt the mesh discretization during forward simulation. Our results show it can accurately predict the dynamics of a wide range of physical systems, including aerodynamics, structural mechanics, and cloth. The model's adaptivity supports learning resolution-independent dynamics and can scale to more complex state spaces at test time. Our method is also highly efficient, running 1-2 orders of magnitude faster than the simulation on which it is trained. Our approach broadens the range of problems on which neural network simulators can operate and promises to improve the efficiency of complex, scientific modeling tasks.","Authors (format: First Last, First Middle Last, ...)":"Tobias Pfaff, Meire Fortunato, Alvaro Sanchez-Gonzalez, Peter W. Battaglia","Bibtex (e.g. @inproceedings...)":"@inproceedings{DBLP:conf/iclr/PfaffFSB21,\n  author    = {Tobias Pfaff and\n               Meire Fortunato and\n               Alvaro Sanchez{-}Gonzalez and\n               Peter W. Battaglia},\n  title     = {Learning Mesh-Based Simulation with Graph Networks},\n  booktitle = {9th International Conference on Learning Representations, {ICLR} 2021,\n               Virtual Event, Austria, May 3-7, 2021},\n  publisher = {OpenReview.net},\n  year      = {2021},\n  url       = {https://openreview.net/forum?id=roNqYL0\\_XP},\n  timestamp = {Wed, 23 Jun 2021 17:36:39 +0200},\n  biburl    = {https://dblp.org/rec/conf/iclr/PfaffFSB21.bib},\n  bibsource = {dblp computer science bibliography, https://dblp.org}\n}","Bibtex Name":"DBLP:conf/iclr/PfaffFSB21","Citation Count":"","Code Release (Github link, or enter \"Coming soon\")":"","Coordinates all at once":"","Data Release (link)":"","Dataset(s) used (e.g. Tanks and Temples)":"","Date released":"18/6/2021","Direct/Indirect Neural Field (one or more dimension built into the network e.g. 2D CNN + z)":"","Does your work use coordinate(s) as neural network input(s)?":"","Email Address":"","Feature-as-input (coordinate samples feature grid, but coordinate is not supplied as input)":"","Frequency/Positional Encoding":"","Geometry proxy (for non-visual computing papers, choose \"N/A\")":"","Inputs":"","Is the PDF linked to arXiv?":"Yes (almost done)","Keywords":"MeshGraphNets, Graph Neural Networks, forward simulation, GNNs, message passing, adaptive remeshing, encoder-processor-decoder, physical simulation, runtime efficiency, neural network simulators","Lighting":"","New entry or update existing?":"","Nickname (e.g. DeepSDF)":"","PDF link (arXiv perferred)":"https://arxiv.org/pdf/2010.03409.pdf","Project webpage link":"","Reconstructs Geometry Only (i.e. no color texture) (for non-visual computing papers, choose \"N/A\")":"","Rendering time (FPS)":"","Supplement PDF (link)":"","Supplement video (link, comma separated if multiple exists)":"","Talk/Video (link, Youtube preferred)":"","Title":"Learning Mesh-Based Simulation with Graph Networks","Training time (hr)":"","UID":"2","Venue & Year (e.g. NeurIPS 2022, ARXIV 2021)":"ICLR 2021","Venue no Year":"ICLR","Year (corresponding to venue e.g. released in 2021, accepted to CVPR 2022, then put \"2022\" for this entry, and \"2021\" for the above)":"2021","\ufeffTimestamp":"18/6/2021 16:32"},{"":"","# of input views (e.g. 18 for 18-camera system)":"","Abstract":"In recent years, there has been a growing interest in using machine learning to overcome the high cost of numerical simulation, with some learned models achieving impressive speed-ups over classical solvers whilst maintaining accuracy. However, these methods are usually tested at low-resolution settings, and it remains to be seen whether they can scale to the costly high-resolution simulations that we ultimately want to tackle. In this work, we propose two complementary approaches to improve the framework from MeshGraphNets, which demonstrated accurate predictions in a broad range of physical systems. MeshGraphNets relies on a message passing graph neural network to propagate information, and this structure becomes a limiting factor for high-resolution simulations, as equally distant points in space become further apart in graph space. First, we demonstrate that it is possible to learn accurate surrogate dynamics of a high-resolution system on a much coarser mesh, both removing the message passing bottleneck and improving performance; and second, we introduce a hierarchical approach (MultiScale MeshGraphNets) which passes messages on two different resolutions (fine and coarse), significantly improving the accuracy of MeshGraphNets while requiring less computational resources.","Authors (format: First Last, First Middle Last, ...)":"Meire Fortunato, Tobias Pfaff, Peter Wirnsberger, Alexander Pritzel, Peter Battaglia","Bibtex (e.g. @inproceedings...)":"@inproceedings{fortunato2022multiscale,\n  title={MultiScale MeshGraphNets},\n  author={Fortunato, Meire and Pfaff, Tobias and Wirnsberger, Peter and Pritzel, Alexander and Battaglia, Peter},\n  booktitle={ICML 2022 2nd AI for Science Workshop},\n  year={2022}\n}","Bibtex Name":"fortunato2022multiscale","Citation Count":"","Code Release (Github link, or enter \"Coming soon\")":"","Coordinates all at once":"","Data Release (link)":"","Dataset(s) used (e.g. Tanks and Temples)":"","Date released":"15/6/2022","Direct/Indirect Neural Field (one or more dimension built into the network e.g. 2D CNN + z)":"","Does your work use coordinate(s) as neural network input(s)?":"","Email Address":"","Feature-as-input (coordinate samples feature grid, but coordinate is not supplied as input)":"","Frequency/Positional Encoding":"","Geometry proxy (for non-visual computing papers, choose \"N/A\")":"","Inputs":"","Is the PDF linked to arXiv?":"No","Keywords":"Multiscale MeshGraphNets, Graph Neural Networks, GNNs, message passing, encoder-processor-decoder, computational efficiency, neural network simulators, computational fluid dynamics, CFD simulation, COMSOL, CylinderFlow","Lighting":"","New entry or update existing?":"","Nickname (e.g. DeepSDF)":"","PDF link (arXiv perferred)":"https://openreview.net/pdf?id=G3TRIsmMhhf","Project webpage link":"","Reconstructs Geometry Only (i.e. no color texture) (for non-visual computing papers, choose \"N/A\")":"","Rendering time (FPS)":"","Supplement PDF (link)":"","Supplement video (link, comma separated if multiple exists)":"","Talk/Video (link, Youtube preferred)":"","Title":"MultiScale MeshGraphNets","Training time (hr)":"","UID":"3","Venue & Year (e.g. NeurIPS 2022, ARXIV 2021)":"ICML-AI4Science 2022","Venue no Year":"ICML-AI4Science","Year (corresponding to venue e.g. released in 2021, accepted to CVPR 2022, then put \"2022\" for this entry, and \"2021\" for the above)":"2022","\ufeffTimestamp":"15/6/2022 00:00"},{"":"","# of input views (e.g. 18 for 18-camera system)":"","Abstract":"Graph-based next-step prediction models have recently been very successful in modeling complex high-dimensional physical systems on irregular meshes. However, due to their short temporal attention span, these models suffer from error accumulation and drift. In this paper, we propose a new method that captures long-term dependencies through a transformer-style temporal attention model. We introduce an encoder-decoder structure to summarize features and create a compact mesh representation of the system state, to allow the temporal model to operate on a low-dimensional mesh representations in a memory efficient manner. Our method outperforms a competitive GNN baseline on several complex fluid dynamics prediction tasks, from sonic shocks to vascular flow. We demonstrate stable rollouts without the need for training noise and show perfectly phase-stable predictions even for very long sequences. More broadly, we believe our approach paves the way to bringing the benefits of attention-based sequence models to solving high-dimensional complex physics tasks.","Authors (format: First Last, First Middle Last, ...)":"Xu Han, Han Gao, Tobias Pfaff, Jian-Xun Wang, Li-Ping Liu","Bibtex (e.g. @inproceedings...)":"@article{DBLP:journals/corr/abs-2201-09113,\n  author    = {Xu Han and\n               Han Gao and\n               Tobias Pffaf and\n               Jian{-}Xun Wang and\n               Li{-}Ping Liu},\n  title     = {Predicting Physics in Mesh-reduced Space with Temporal Attention},\n  journal   = {CoRR},\n  volume    = {abs/2201.09113},\n  year      = {2022},\n  url       = {https://arxiv.org/abs/2201.09113},\n  eprinttype = {arXiv},\n  eprint    = {2201.09113},\n  timestamp = {Tue, 01 Feb 2022 14:59:01 +0100},\n  biburl    = {https://dblp.org/rec/journals/corr/abs-2201-09113.bib},\n  bibsource = {dblp computer science bibliography, https://dblp.org}\n}","Bibtex Name":"DBLP:journals/corr/abs-2201-09113","Citation Count":"","Code Release (Github link, or enter \"Coming soon\")":"","Coordinates all at once":"","Data Release (link)":"","Dataset(s) used (e.g. Tanks and Temples)":"","Date released":"26/5/2022","Direct/Indirect Neural Field (one or more dimension built into the network e.g. 2D CNN + z)":"","Does your work use coordinate(s) as neural network input(s)?":"","Email Address":"","Feature-as-input (coordinate samples feature grid, but coordinate is not supplied as input)":"","Frequency/Positional Encoding":"","Geometry proxy (for non-visual computing papers, choose \"N/A\")":"","Inputs":"","Is the PDF linked to arXiv?":"Yes","Keywords":"Graph Neural Networks, transformers, autoregressive, multi-head attention, temporal attention, GNNs, message passing, encoder-processor-decoder, computational efficiency, neural network simulators, computational fluid dynamics, CFD simulation, cylinderflow, mesh, graph mesh reducer, autoencoder","Lighting":"","New entry or update existing?":"","Nickname (e.g. DeepSDF)":"","PDF link (arXiv perferred)":"https://arxiv.org/pdf/2201.09113.pdf","Project webpage link":"","Reconstructs Geometry Only (i.e. no color texture) (for non-visual computing papers, choose \"N/A\")":"","Rendering time (FPS)":"","Supplement PDF (link)":"","Supplement video (link, comma separated if multiple exists)":"","Talk/Video (link, Youtube preferred)":"","Title":"Predicting Physics in Mesh-reduced Space with Temporal Attention","Training time (hr)":"","UID":"4","Venue & Year (e.g. NeurIPS 2022, ARXIV 2021)":"ICLR 2022","Venue no Year":"ICLR","Year (corresponding to venue e.g. released in 2021, accepted to CVPR 2022, then put \"2022\" for this entry, and \"2021\" for the above)":"2022","\ufeffTimestamp":"26/5/2022 17:14"}]
